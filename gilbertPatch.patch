From 183057034150a8538f679a4c7cb7a10b68460bb8 Mon Sep 17 00:00:00 2001
From: Till Rohrmann <till.rohrmann@mailbox.tu-berlin.de>
Date: Wed, 12 Feb 2014 18:59:04 +0100
Subject: [PATCH] Modifications for Stratosphere to support Gilbert: PlanNodes
 which belong to an iteration and do not lie on a dynamic path are
 instantiated as RegularPactTask. This avoids that
 checkForTerminationAndResetEndOfSuperstepState in AbstractIterativePactTask
 fails because there are no iterative inputs. Removed private modifier from
 member sink in ScalaSink so that user programs can modify the GenericDataSink
 after calling write on a DataSet, e.g., setting the name or compiler hints.
 Furthermore, the write method of DataSinkOperator got an additional parameter
 name to set the name of the sink directly. Extending the GraphCreatingVisitor
 by a HashMap<Operator, OptimizerNode> parameter which represents the current
 closure environment. This allows that in recursive calls, e.g., in the case
 of an iteration step function the referenced objects of the closure are
 correctly resolved instead of creating them again. This also partly fixes the
 problem of multiple data sinks. The problem was that objects referenced
 within the iterative step function are not recognized as being part of the
 data flow. This means they could not be outputted. However, the correct
 referencing and the forwarding of open branches from the nextPartialSolution
 node to its parent BulkIterationNode resolves the problem. Additionally the
 branchPlan of the rootOfStepFunction in BulkIterationPlanNode is merged with
 the branchPlan of BulkIterationPlanNode. And the iterative step function is
 now taken into consideration when the method hasDamOnPathDownTo is called.
 This makes the getAlternativePlans and instantiate method the PlanNodes
 working. Fixed the PlanCacheCleaner so that it does not clean the cache of
 non dynamic PlanNodes. Otherwise new PlanNodes for non-dynamic OptimizerNodes
 are generated which causes the getAlternativePlans to fail. Therefore, the
 StaticDynamicPathIdentifier has to correctly start at the internal
 solutionSetDelta node of the WorksetIterationNode and not the
 solutionSetDeltaNode generated by the recursive graph creator. The reason is
 that internally another unaryOperatorNode is connected upstream.

---
 pom.xml                                            |   4 +-
 .../eu/stratosphere/compiler/PactCompiler.java     |  34 +++--
 .../compiler/dag/BulkIterationNode.java            |  18 +++
 .../compiler/plan/BulkIterationPlanNode.java       |  18 ++-
 .../plantranslate/NepheleJobGraphGenerator.java    |   6 +-
 .../pact/compiler/BranchingPlansCompilerTest.java  |  36 +++++
 .../compiler/WorksetIterationsCompilerTest.java    |   6 +-
 .../scala/eu/stratosphere/api/scala/DataSet.scala  |   1 +
 .../scala/eu/stratosphere/api/scala/DataSink.scala |   9 +-
 .../stratosphere/api/scala/LiteralDataSource.scala |  35 +++++
 .../api/scala/io/LiteralBaseStatistics.scala       |   9 ++
 .../api/scala/io/LiteralInputFormat.scala          | 146 +++++++++++++++++++++
 .../api/scala/io/LiteralInputSplit.scala           |  34 +++++
 13 files changed, 336 insertions(+), 20 deletions(-)
 create mode 100644 stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/LiteralDataSource.scala
 create mode 100644 stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralBaseStatistics.scala
 create mode 100644 stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputFormat.scala
 create mode 100644 stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputSplit.scala

diff --git a/pom.xml b/pom.xml
index a0ad9ae..89c04fe 100644
--- a/pom.xml
+++ b/pom.xml
@@ -263,8 +263,8 @@
 				<artifactId>maven-compiler-plugin</artifactId>
 				<version>3.1</version>
 				<configuration>
-					<source>1.6</source>
-					<target>1.6</target>
+					<source>1.7</source>
+					<target>1.7</target>
 				</configuration>
 			</plugin>
 
diff --git a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/PactCompiler.java b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/PactCompiler.java
index 02f635b..6d805e0 100644
--- a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/PactCompiler.java
+++ b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/PactCompiler.java
@@ -794,10 +794,19 @@ public class PactCompiler {
 			this(null, false, statistics, maxMachines, defaultParallelism, computeEstimates);
 		}
 		
+		GraphCreatingVisitor(GraphCreatingVisitor parent, boolean forceDOP, DataStatistics statistics, int maxMachines,
+		    int defaultParallelism, boolean computeEstimates){
+		  this(parent, forceDOP, statistics, maxMachines, defaultParallelism, computeEstimates, null);
+		}
+		
 		GraphCreatingVisitor(GraphCreatingVisitor parent, boolean forceDOP,
-			DataStatistics statistics, int maxMachines, int defaultParallelism, boolean computeEstimates)
+			DataStatistics statistics, int maxMachines, int defaultParallelism, boolean computeEstimates, 
+			HashMap<Operator, OptimizerNode> closure)
 		{
-			this.con2node = new HashMap<Operator, OptimizerNode>();
+		  if(closure == null)
+		    this.con2node = new HashMap<Operator, OptimizerNode>();
+		  else
+		    this.con2node = closure;
 			this.sources = new ArrayList<DataSourceNode>(4);
 			this.sinks = new ArrayList<DataSinkNode>(2);
 			this.statistics = statistics;
@@ -966,9 +975,16 @@ public class PactCompiler {
 				final BulkIterationNode iterNode = (BulkIterationNode) n;
 				final BulkIteration iter = iterNode.getIterationContract();
 				
+				// compute the closure of the anonymous function
+				HashMap<Operator, OptimizerNode> closure = new HashMap<Operator, OptimizerNode>(this.con2node);
+				for(Operator op: iter.getInputs()){
+				  closure.remove(op);
+				}
+				
 				// first, recursively build the data flow for the step function
 				final GraphCreatingVisitor recursiveCreator = new GraphCreatingVisitor(this, true,
-					this.statistics, this.maxMachines, iterNode.getDegreeOfParallelism(), this.computeEstimates);
+					this.statistics, this.maxMachines, iterNode.getDegreeOfParallelism(), this.computeEstimates, 
+					closure);
 				iter.getNextPartialSolution().accept(recursiveCreator);
 				
 				OptimizerNode rootOfStepFunction = recursiveCreator.con2node.get(iter.getNextPartialSolution());
@@ -1062,7 +1078,7 @@ public class PactCompiler {
 				// go over the contained data flow and mark the dynamic path nodes
 				StaticDynamicPathIdentifier pathIdentifier = new StaticDynamicPathIdentifier(iterNode.getCostWeight());
 				nextWorksetNode.accept(pathIdentifier);
-				solutionSetDeltaNode.accept(pathIdentifier);
+				iterNode.getSolutionSetDelta().accept(pathIdentifier);
 			}
 		}
 
@@ -1200,11 +1216,11 @@ public class PactCompiler {
 		 */
 		@Override
 		public void postVisit(OptimizerNode node) {
-			node.computeUnclosedBranchStack();
-			
-			if (node instanceof IterationNode) {
-				((IterationNode) node).acceptForStepFunction(this);
-			}
+		  if (node instanceof IterationNode) {
+        ((IterationNode) node).acceptForStepFunction(this);
+      }
+		  
+		  node.computeUnclosedBranchStack();
 		}
 	};
 	
diff --git a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/dag/BulkIterationNode.java b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/dag/BulkIterationNode.java
index cf98f2a..693b3df 100644
--- a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/dag/BulkIterationNode.java
+++ b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/dag/BulkIterationNode.java
@@ -13,6 +13,7 @@
 
 package eu.stratosphere.compiler.dag;
 
+import java.util.ArrayList;
 import java.util.Collections;
 import java.util.Iterator;
 import java.util.List;
@@ -117,6 +118,23 @@ public class BulkIterationNode extends SingleInputNode implements IterationNode
 	// --------------------------------------------------------------------------------------------
 	
 	@Override
+  public void computeUnclosedBranchStack() {
+    if (this.openBranches != null) {
+      return;
+    }
+
+    addClosedBranches(getPredecessorNode().closedBranchingNodes);
+    addClosedBranches(getNextPartialSolution().closedBranchingNodes);
+    
+    List<UnclosedBranchDescriptor> result1 = getPredecessorNode().getBranchesForParent(this.inConn);
+    List<UnclosedBranchDescriptor> result2 = getNextPartialSolution().getBranchesForParent(this.rootConnection);
+    
+    ArrayList<UnclosedBranchDescriptor> result = new ArrayList<UnclosedBranchDescriptor>();
+    mergeLists(result1, result2, result);
+    this.openBranches = result.isEmpty() ? Collections.<UnclosedBranchDescriptor>emptyList() : result;
+  }
+	
+	@Override
 	public String getName() {
 		return "Bulk Iteration";
 	}
diff --git a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plan/BulkIterationPlanNode.java b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plan/BulkIterationPlanNode.java
index e38d391..166580a 100644
--- a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plan/BulkIterationPlanNode.java
+++ b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plan/BulkIterationPlanNode.java
@@ -16,9 +16,12 @@ package eu.stratosphere.compiler.plan;
 import static eu.stratosphere.compiler.plan.PlanNode.SourceAndDamReport.FOUND_SOURCE;
 import static eu.stratosphere.compiler.plan.PlanNode.SourceAndDamReport.FOUND_SOURCE_AND_DAM;
 
+import java.util.Map;
+
 import eu.stratosphere.api.common.typeutils.TypeSerializerFactory;
 import eu.stratosphere.compiler.costs.Costs;
 import eu.stratosphere.compiler.dag.BulkIterationNode;
+import eu.stratosphere.compiler.dag.OptimizerNode;
 import eu.stratosphere.pact.runtime.task.DriverStrategy;
 import eu.stratosphere.util.Visitor;
 
@@ -40,7 +43,19 @@ public class BulkIterationPlanNode extends SingleInputPlanNode implements Iterat
 		super(template, nodeName, input, DriverStrategy.NONE);
 		this.partialSolutionPlanNode = pspn;
 		this.rootOfStepFunction = rootOfStepFunction;
+		
+		mergeBranchPlanMaps();
 	}
+	
+	private void mergeBranchPlanMaps() {
+	  if(rootOfStepFunction.branchPlan != null){
+	    for(Map.Entry<OptimizerNode, PlanNode> entry: rootOfStepFunction.branchPlan.entrySet()){
+	      if(!this.branchPlan.containsKey(entry.getKey())){
+	        this.branchPlan.put(entry.getKey(), entry.getValue());
+	      }
+	    }
+	  }
+  }
 
 	// --------------------------------------------------------------------------------------------
 	
@@ -93,7 +108,8 @@ public class BulkIterationPlanNode extends SingleInputPlanNode implements Iterat
 			// we always have a dam in the back channel
 			return FOUND_SOURCE_AND_DAM;
 		} else {
-			return fromOutside;
+		  SourceAndDamReport stepFunction = this.rootOfStepFunction.hasDamOnPathDownTo(source);
+      return stepFunction;
 		}
 	}
 
diff --git a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plantranslate/NepheleJobGraphGenerator.java b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plantranslate/NepheleJobGraphGenerator.java
index 48c55f9..82d6e79 100644
--- a/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plantranslate/NepheleJobGraphGenerator.java
+++ b/stratosphere-compiler/src/main/java/eu/stratosphere/compiler/plantranslate/NepheleJobGraphGenerator.java
@@ -753,7 +753,8 @@ public class NepheleJobGraphGenerator implements Visitor<PlanNode> {
 		} else {
 			// create task vertex
 			vertex = new JobTaskVertex(taskName, this.jobGraph);
-			vertex.setTaskClass(this.currentIteration == null ? RegularPactTask.class : IterationIntermediatePactTask.class);
+			vertex.setTaskClass(this.currentIteration == null || !node.isOnDynamicPath() ? RegularPactTask.class : 
+			  IterationIntermediatePactTask.class);
 			config = new TaskConfig(vertex.getConfiguration());
 			config.setDriver(ds.getDriverClass());
 		}
@@ -778,7 +779,8 @@ public class NepheleJobGraphGenerator implements Visitor<PlanNode> {
 		final DriverStrategy ds = node.getDriverStrategy();
 		final JobTaskVertex vertex = new JobTaskVertex(taskName, this.jobGraph);
 		final TaskConfig config = new TaskConfig(vertex.getConfiguration());
-		vertex.setTaskClass(this.currentIteration == null ? RegularPactTask.class : IterationIntermediatePactTask.class);
+		vertex.setTaskClass(this.currentIteration == null || !node.isOnDynamicPath() ? RegularPactTask.class : 
+		  IterationIntermediatePactTask.class);
 		
 		// set user code
 		config.setStubWrapper(node.getPactContract().getUserCodeWrapper());
diff --git a/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/BranchingPlansCompilerTest.java b/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/BranchingPlansCompilerTest.java
index fea6135..b17d975 100644
--- a/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/BranchingPlansCompilerTest.java
+++ b/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/BranchingPlansCompilerTest.java
@@ -662,4 +662,40 @@ public class BranchingPlansCompilerTest extends CompilerTestBase {
 			Assert.fail(e.getMessage());
 		}
 	}
+	
+	@Test
+	public void testClosure() {
+	  FileDataSource sourceA = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 1");
+	  FileDataSource sourceB = new FileDataSource(DummyInputFormat.class, IN_FILE, "Source 2");
+	  
+	  FileDataSink sink1 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceA, "Sink 1");
+	  FileDataSink sink2 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, sourceB, "Sink 2");
+	  
+	  BulkIteration iteration = new BulkIteration("Loop");
+	  iteration.setInput(sourceA);
+	  iteration.setMaximumNumberOfIterations(10);
+	  
+	  CrossOperator stepFunction = CrossOperator.builder(DummyCrossStub.class).name("StepFunction").
+	      input1(iteration.getPartialSolution()).
+	      input2(sourceB).
+	      build();
+	  
+	  iteration.setNextPartialSolution(stepFunction);
+	  
+	  FileDataSink sink3 = new FileDataSink(DummyOutputFormat.class, OUT_FILE, iteration, "Sink 3");
+	  
+	  List<GenericDataSink> sinks = new ArrayList<GenericDataSink>();
+	  sinks.add(sink1);
+	  sinks.add(sink2);
+	  sinks.add(sink3);
+	  
+	  Plan plan = new Plan(sinks);
+	  
+	  try{
+	    compileNoStats(plan);
+	  }catch(Exception e){
+	    e.printStackTrace();
+	    Assert.fail(e.getMessage());
+	  }
+	}
 }
diff --git a/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/WorksetIterationsCompilerTest.java b/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/WorksetIterationsCompilerTest.java
index 00a1c85..de7a352 100644
--- a/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/WorksetIterationsCompilerTest.java
+++ b/stratosphere-compiler/src/test/java/eu/stratosphere/pact/compiler/WorksetIterationsCompilerTest.java
@@ -59,7 +59,7 @@ public class WorksetIterationsCompilerTest extends CompilerTestBase {
 	private final FieldList list0 = new FieldList(0);
 
 	@Test
-	public void testWithDeferredSoltionSetUpdateWithMapper() {
+	public void testWithDeferredSolutionSetUpdateWithMapper() {
 		Plan plan = getTestPlan(false, true);
 		
 		OptimizedPlan oPlan;
@@ -105,7 +105,7 @@ public class WorksetIterationsCompilerTest extends CompilerTestBase {
 	}
 	
 	@Test
-	public void testWithDeferredSoltionSetUpdateWithNonPreservingJoin() {
+	public void testWithDeferredSolutionSetUpdateWithNonPreservingJoin() {
 		Plan plan = getTestPlan(false, false);
 		
 		OptimizedPlan oPlan;
@@ -149,7 +149,7 @@ public class WorksetIterationsCompilerTest extends CompilerTestBase {
 	}
 	
 	@Test
-	public void testWithDirectSoltionSetUpdate() {
+	public void testWithDirectSolutionSetUpdate() {
 		Plan plan = getTestPlan(true, false);
 		
 		OptimizedPlan oPlan;
diff --git a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSet.scala b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSet.scala
index 28e3596..4ea1d19 100644
--- a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSet.scala
+++ b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSet.scala
@@ -50,5 +50,6 @@ class DataSet[T] (val contract: Operator with ScalaOperator[T]) {
   def iterateWithDelta[SolutionKey, WorksetItem](workset: DataSet[WorksetItem], solutionSetKey: T => SolutionKey, stepFunction: (DataSet[T], DataSet[WorksetItem]) => (DataSet[T], DataSet[WorksetItem]), maxIterations: Int) = macro WorksetIterateMacros.iterateWithDelta[T, SolutionKey, WorksetItem]
   
   def write(url: String, format: ScalaOutputFormat[T]) = DataSinkOperator.write(this, url, format)
+  def write(url: String, format: ScalaOutputFormat[T], name: String) = DataSinkOperator.write(this, url, format, name)
   
 }
\ No newline at end of file
diff --git a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSink.scala b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSink.scala
index c2b0e57..2a31085 100644
--- a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSink.scala
+++ b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/DataSink.scala
@@ -23,12 +23,15 @@ import eu.stratosphere.api.common.io.FileOutputFormat
 import eu.stratosphere.api.common.operators.GenericDataSink
 
 object DataSinkOperator {
+  
+  val DEFAULT_DATASINKOPERATOR_NAME = "<Unnamed Scala Data Sink>"
 
-  def write[In](input: DataSet[In], url: String, format: ScalaOutputFormat[In]): ScalaSink[In] = {
+  def write[In](input: DataSet[In], url: String, format: ScalaOutputFormat[In], 
+      name: String = DEFAULT_DATASINKOPERATOR_NAME): ScalaSink[In] = {
     val uri = getUri(url)
 
     val ret = uri.getScheme match {
-      case "file" | "hdfs" => new FileDataSink(format.asInstanceOf[FileOutputFormat[_]], uri.toString, input.contract)
+      case "file" | "hdfs" => new FileDataSink(format.asInstanceOf[FileOutputFormat[_]], uri.toString, input.contract, name)
           with OneInputScalaOperator[In, Nothing] {
 
         def getUDF = format.getUDF
@@ -47,7 +50,7 @@ object DataSinkOperator {
   }
 }
 
-class ScalaSink[In] private[scala] (private[scala] val sink: GenericDataSink)
+class ScalaSink[In] private[scala] (val sink: GenericDataSink)
 
 trait ScalaOutputFormat[In] { this: OutputFormat[_] =>
   def getUDF: UDF1[In, Nothing]
diff --git a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/LiteralDataSource.scala b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/LiteralDataSource.scala
new file mode 100644
index 0000000..f7f945f
--- /dev/null
+++ b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/LiteralDataSource.scala
@@ -0,0 +1,35 @@
+package eu.stratosphere.api.scala
+
+import eu.stratosphere.api.common.operators.GenericDataSource
+import eu.stratosphere.api.scala.io.LiteralInputFormat
+import eu.stratosphere.api.common.operators.util.FieldSet
+
+object LiteralDataSource {
+  
+  private val DEFAULT_NAME = "<Unnamed literal data source>"
+    
+  def apply[Out](literalValue: Out, format: LiteralInputFormat[Out]): DataSet[Out] with OutputHintable[Out] = {
+    val result = new LiteralDataSource[Out]( format, List(literalValue))
+    result.setName(s"Literal data source: $literalValue")
+    result.getCompilerHints().setDistinctCount(new FieldSet(0), 1)
+    new DataSet(result) with OutputHintable[Out] {}
+  }
+  
+  def apply[Out](literalValues: Iterable[Out], format: LiteralInputFormat[Out]): DataSet[Out] with OutputHintable[Out] = {
+    val result =new LiteralDataSource[Out](format,literalValues)
+    result.setName(s"Literal data source: $literalValues")
+    result.getCompilerHints().setDistinctCount(new FieldSet(0), literalValues.size)
+    new DataSet(result) with OutputHintable[Out] {}
+  }
+}
+
+class LiteralDataSource[Out](val format: LiteralInputFormat[Out], val values: Iterable[Out], name: String) 
+extends GenericDataSource[LiteralInputFormat[Out]](format, name) with ScalaOperator[Out] {
+  
+  format.setData(values)
+  
+  def this(format: LiteralInputFormat[Out], values: Iterable[Out]) = this(format,values, LiteralDataSource.DEFAULT_NAME)
+    
+  override def getUDF = format.getUDF
+  override def persistConfiguration() = format.persistConfiguration(this.getParameters())
+}
\ No newline at end of file
diff --git a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralBaseStatistics.scala b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralBaseStatistics.scala
new file mode 100644
index 0000000..54e9acf
--- /dev/null
+++ b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralBaseStatistics.scala
@@ -0,0 +1,9 @@
+package eu.stratosphere.api.scala.io
+
+import eu.stratosphere.api.common.io.statistics.BaseStatistics
+
+case class LiteralBaseStatistics(totalInputSize: Long, numberOfRecords: Long, averageRecordWidth: Double) extends BaseStatistics{
+  override def getTotalInputSize = totalInputSize
+  override def getNumberOfRecords = numberOfRecords
+  override def getAverageRecordWidth = averageRecordWidth.toFloat
+}
\ No newline at end of file
diff --git a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputFormat.scala b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputFormat.scala
new file mode 100644
index 0000000..5dacb9b
--- /dev/null
+++ b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputFormat.scala
@@ -0,0 +1,146 @@
+package eu.stratosphere.api.scala.io
+
+import scala.reflect.macros.Context
+import eu.stratosphere.api.scala.codegen.MacroContextHolder
+import eu.stratosphere.api.scala.operators.ScalaInputFormatBase
+import scala.language.experimental.macros
+import eu.stratosphere.types.Record
+import eu.stratosphere.api.common.io.InputFormat
+import java.io.IOException
+import eu.stratosphere.types.Value
+import org.apache.commons.logging.LogFactory
+import eu.stratosphere.api.common.io.UnsplittableInput
+import eu.stratosphere.api.common.io.statistics.BaseStatistics
+import eu.stratosphere.configuration.Configuration
+import eu.stratosphere.api.scala.ScalaInputFormat
+import eu.stratosphere.api.scala.analysis.UDT
+import eu.stratosphere.api.scala.analysis.UDF0
+import eu.stratosphere.api.scala.analysis.UDTSerializer
+import eu.stratosphere.core.io.GenericInputSplit
+import eu.stratosphere.api.java.record.io.GenericInputFormat
+
+object LiteralInputFormat {
+
+  def apply[Out](): LiteralInputFormat[Out] = macro impl[Out]
+
+  def impl[Out: c.WeakTypeTag](c: Context)(): c.Expr[LiteralInputFormat[Out]] = {
+    import c.universe._
+
+    val slave = MacroContextHolder.newMacroHelper(c)
+
+    val (udtOut, createUdtOut) = slave.mkUdtClass[Out]
+
+    val pact4sFormat = reify {
+      new LiteralInputFormat[Out] {
+        override val udt = c.Expr(createUdtOut).splice
+      }
+    }
+
+    val result = c.Expr[LiteralInputFormat[Out]](Block(List(udtOut), pact4sFormat.tree))
+
+    return result
+  }
+}
+
+@SerialVersionUID(2L)
+trait LiteralInputFormat[Out] extends GenericInputFormat with ScalaInputFormat[Out] {
+  val LOG = LogFactory.getLog(this.getClass())
+
+  private var data: Iterable[Out] = _
+  private var startIndex: Int = -1
+  private var endIndex: Int = -1
+  protected var iterator: Iterator[Out] = null
+  protected val udt: UDT[Out]
+  lazy val udf: UDF0[Out] = new UDF0(udt)
+  def getUDF: UDF0[Out] = udf
+  protected var serializer: UDTSerializer[Out] = _
+  protected var outputLength: Int = _
+
+  override def configure(configuration: Configuration) {
+    this.outputLength = udf.getOutputLength
+    this.serializer = udf.getOutputSerializer
+  }
+
+  def setData(data: Iterable[Out]) {
+    this.data = data
+  }
+
+  @throws(classOf[IOException])
+  override def open(genericSplit: GenericInputSplit) {
+    if (!genericSplit.isInstanceOf[LiteralInputSplit]) {
+      throw new IOException("Input split has to of type LiteralInputSplit")
+    }
+
+    val split = genericSplit.asInstanceOf[LiteralInputSplit]
+
+    if (split == null) {
+      throw new IllegalArgumentException("Input split cannot be null")
+    }
+    if (split.startIndex < 0) {
+      throw new IllegalArgumentException("Split start index cannot be less than 0")
+    }
+    if (split.startIndex > split.endIndex) {
+      throw new IllegalArgumentException("Split start index cannot be greater than the end index")
+    }
+    if (split.endIndex > data.size) {
+      throw new IllegalArgumentException("Split end index out of bounds")
+    }
+
+    if (endIndex != -1 && endIndex <= split.startIndex) {
+      iterator.drop(split.startIndex - endIndex)
+    } else {
+      iterator = data.iterator
+      iterator.drop(split.startIndex)
+    }
+
+    startIndex = split.startIndex
+    endIndex = split.endIndex
+  }
+
+  override def close() {
+    startIndex = -1
+    endIndex = -1
+    iterator = null
+  }
+
+  override def reachedEnd(): Boolean = {
+    !iterator.hasNext
+  }
+
+  override def createInputSplits(numSplits: Int): Array[GenericInputSplit] = {
+    if (numSplits < 1) {
+      throw new IllegalArgumentException("Number input splits has to greater than 0")
+    }
+
+    val actualSplits = if (this.isInstanceOf[UnsplittableInput]) 1 else math.min(numSplits, data.size)
+    val result = new Array[GenericInputSplit](actualSplits)
+    val fraction = data.size.toDouble / actualSplits
+    var counter = 0.0
+
+    for (split <- 0 until actualSplits) {
+      val startIndex = counter.toInt
+      counter += fraction
+      val endIndex = counter.toInt
+      val newSplit = new LiteralInputSplit(split, startIndex, endIndex)
+      result(split) = newSplit
+    }
+
+    result
+  }
+
+  @throws(classOf[IOException])
+  override def getStatistics(cachedStatistics: BaseStatistics): BaseStatistics = {
+    if (cachedStatistics == null) {
+      LiteralBaseStatistics(0, data.size, 0)
+    } else {
+      cachedStatistics
+    }
+  }
+
+  override def nextRecord(record: Record): Boolean = {
+    record.setNumFields(outputLength)
+    serializer.serialize(iterator.next(), record)
+    true
+  }
+
+}
\ No newline at end of file
diff --git a/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputSplit.scala b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputSplit.scala
new file mode 100644
index 0000000..4174051
--- /dev/null
+++ b/stratosphere-scala/src/main/scala/eu/stratosphere/api/scala/io/LiteralInputSplit.scala
@@ -0,0 +1,34 @@
+package eu.stratosphere.api.scala.io
+
+import eu.stratosphere.core.io.InputSplit
+import java.io.DataInput
+import java.io.IOException
+import java.io.DataOutput
+import eu.stratosphere.core.io.GenericInputSplit
+
+class LiteralInputSplit(splitNumber: Int, splitStartIndex: Int, splitEndIndex: Int) 
+extends GenericInputSplit {
+  number = splitNumber
+  var startIndex = splitStartIndex
+  var endIndex = splitEndIndex
+  
+  def this() = this(-1,-1,-1)
+  
+  @throws(classOf[IOException])
+  override def read(in: DataInput) {
+    super.read(in)
+    startIndex = in.readInt()
+    endIndex = in.readInt()
+  }
+  
+  @throws(classOf[IOException])
+  override def write(out: DataOutput){
+    super.write(out)
+    out.writeInt(startIndex)
+    out.writeInt(endIndex)
+  }
+  
+  override def toString = {
+    "[" + number + "]" + startIndex + "->" + endIndex 
+  }
+}
\ No newline at end of file
-- 
1.8.3.4 (Apple Git-47)

